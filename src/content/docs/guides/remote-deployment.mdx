---
title: Remote Deployment
description: Run msgvault in Docker on a remote host and provision it from a machine with a browser.
---

msgvault supports a remote-first workflow where you configure a remote instance using a local browser session, then deploy and sync on headless hardware. This works with any always-on host: a NAS (a good choice for RAID fault tolerance), a cloud VM, a Raspberry Pi, or any Linux server with Docker.

The flow is built on three capabilities:

- `msgvault setup` interactive wizard that can generate a deployment bundle
- `msgvault export-token` to upload OAuth tokens over API
- `[remote]` config for running local CLI commands against a remote server

## Setup Flow Overview

1. Configure OAuth credentials and choose the remote target in `msgvault setup`
2. Copy the generated `nas-bundle` directory to your remote host
3. Run `docker-compose up -d` on the remote host
4. Add a Gmail account locally and export the token to the remote host
5. Trigger sync and use the `msgvault` API or CLI in remote mode

## 1) Interactive Setup and Bundle Generation

Run the wizard once after installing msgvault:

```bash
msgvault setup
```

If you already have OAuth configured, you can skip that step during the flow.
If you choose to configure a remote server, the wizard:

- prompts for remote hostname/IP and port
- generates a random API key
- creates `<MSGVAULT_HOME>/nas-bundle`
- writes a server-ready `config.toml`
- copies `client_secret.json` into the bundle
- writes a `docker-compose.yml` for deployment
- prints the command for uploading the OAuth token once the account is added

### Bundle Contents

From the local machine, the wizard creates:

```bash
ls -la ~/.msgvault/nas-bundle
```

- `config.toml` — preconfigured server config for the remote container
- `client_secret.json` — copied OAuth credentials
- `docker-compose.yml` — ready-to-run Compose service

### Example `config.toml` Generated by Setup

```toml
[server]
bind_addr = "0.0.0.0"
api_port = 8080
api_key = "<32-byte-hex-key>"

[oauth]
client_secrets = "/data/client_secret.json"

[sync]
rate_limit_qps = 5

# Accounts will be added automatically when you export tokens.
# [[accounts]] can be added manually if needed.
```

### Example `docker-compose.yml` Generated by Setup

```yaml
version: "3.8"

services:
  msgvault:
    image: ghcr.io/wesm/msgvault:latest
    container_name: msgvault
    user: root
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - ./:/data
    environment:
      - TZ=America/Los_Angeles
      - MSGVAULT_HOME=/data
    command: ["serve"]
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
```

## 2) Deploy to Remote Host

Copy the bundle and start services via SSH:

```bash
# Copy the generated bundle
scp -r ~/.msgvault/nas-bundle user@remote-host:/opt/msgvault

# Start services on the remote host
ssh user@remote-host "cd /opt/msgvault && docker-compose up -d"
```

Verify the service:

```bash
curl http://remote-host:8080/health
```

:::note[NAS-specific paths]
On Synology, QNAP, and similar NAS devices the Docker volume path varies. For example, Synology typically uses `/volume1/docker/msgvault`.
:::

## 3) Provision Gmail Tokens

For each mailbox:

1. Add account locally (requires browser):

```bash
msgvault add-account you@gmail.com
```

2. Export the token to the remote endpoint:

```bash
msgvault export-token you@gmail.com --to http://remote-host:8080 --api-key YOUR_API_KEY
```

The command uploads to `POST /api/v1/auth/token/{email}` and also posts to `POST /api/v1/accounts` to register:

- default sync schedule `0 2 * * *`
- account enabled

If your remote host is on a trusted LAN and you prefer HTTP, use `--allow-insecure`:

```bash
msgvault export-token you@gmail.com --to http://remote-host:8080 --api-key YOUR_API_KEY --allow-insecure
```

If you did not configure remote details during setup, you can also set:

```bash
export MSGVAULT_REMOTE_URL=https://remote-host:8080
export MSGVAULT_REMOTE_API_KEY=YOUR_API_KEY
msgvault export-token you@gmail.com
```

## 4) Start and Sync

On the remote container, run sync manually after export:

```bash
# one-time trigger
curl -X POST -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/sync/you@gmail.com

# confirm account schedule/status
curl -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/scheduler/status
```

Background sync runs on schedule after the first full archive is created.

## Using the Local CLI Against Remote

When your local machine config has:

```toml
[remote]
url = "http://remote-host:8080"
api_key = "YOUR_API_KEY"
allow_insecure = true
```

`search`, `stats`, `list-accounts`, and `show-message` automatically query the remote API.
Use `--local` if you explicitly want to query local SQLite instead.

## Security Notes

- The remote server config still enforces `api_key` for non-loopback API access.
- `http://` is accepted for `export-token` only when `--allow-insecure` is used.
- Prefer HTTPS if the endpoint is exposed beyond trusted networks.
- The generated bundle sets `user: root` in Docker Compose, which works around common NAS ACL quirks (for example Synology). On a standard Linux server you can change this to a non-root user.

## Troubleshooting

### Export fails with HTTPS required

`msgvault export-token` requires HTTPS by default. If your endpoint is `http://`, add `--allow-insecure`.

### 401/authorization errors from export

Check that `X-API-Key` matches the server's `[server] api_key` and that `/api/v1/auth/token/{email}` is reachable.

### Account not syncing after import

Verify the account exists in the server config:

```bash
curl -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/accounts
```

If missing, re-run `export-token`, which also posts account metadata.
