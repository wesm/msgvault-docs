---
title: Remote Deployment
description: Run msgvault in Docker on a remote host and provision it from a machine with a browser.
---

msgvault supports a remote-first workflow where you configure a remote instance using a local browser session, then deploy and sync on headless hardware. This works with any always-on host: a NAS (a good choice for RAID fault tolerance), a cloud VM, a Raspberry Pi, or any Linux server with Docker.

The flow is built on three capabilities:

- `msgvault setup` interactive wizard that can generate a deployment bundle
- `msgvault export-token` to upload OAuth tokens over API
- `[remote]` config for running local CLI commands against a remote server

## Setup Flow Overview

1. Configure OAuth credentials and choose the remote target in `msgvault setup`
2. Copy the generated `nas-bundle` directory to your remote host
3. Run `docker-compose up -d` on the remote host
4. Add a Gmail account locally and export the token to the remote host
5. Run the initial full sync on the remote host
6. Use the `msgvault` API or CLI in remote mode

## 1) Interactive Setup and Bundle Generation

Run the wizard once after installing msgvault:

```bash
msgvault setup
```

If you already have OAuth configured, you can skip that step during the flow.
If you choose to configure a remote server, the wizard:

- prompts for remote hostname/IP and port
- generates a random API key
- creates `<MSGVAULT_HOME>/nas-bundle`
- writes a server-ready `config.toml`
- copies `client_secret.json` into the bundle
- writes a `docker-compose.yml` for deployment
- prints the command for uploading the OAuth token once the account is added

### Bundle Contents

From the local machine, the wizard creates:

```bash
ls -la ~/.msgvault/nas-bundle
```

- `config.toml` — preconfigured server config for the remote container
- `client_secret.json` — copied OAuth credentials
- `docker-compose.yml` — ready-to-run Compose service

### Example `config.toml` Generated by Setup

```toml
[server]
bind_addr = "0.0.0.0"
api_port = 8080
api_key = "<32-byte-hex-key>"

[oauth]
client_secrets = "/data/client_secret.json"

[sync]
rate_limit_qps = 5

# Accounts will be added automatically when you export tokens.
# [[accounts]] can be added manually if needed.
```

### Example `docker-compose.yml` Generated by Setup

```yaml
version: "3.8"

services:
  msgvault:
    image: ghcr.io/wesm/msgvault:latest
    container_name: msgvault
    user: root
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - ./:/data
    environment:
      - TZ=America/Los_Angeles
      - MSGVAULT_HOME=/data
    command: ["serve"]
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
```

## 2) Deploy to Remote Host

Copy the bundle and start services via SSH:

```bash
# Copy the generated bundle
scp -r ~/.msgvault/nas-bundle user@remote-host:/opt/msgvault

# Start services on the remote host
ssh user@remote-host "cd /opt/msgvault && docker-compose up -d"
```

Verify the service:

```bash
curl http://remote-host:8080/health
```

:::note[NAS-specific paths]
On Synology, QNAP, and similar NAS devices the Docker volume path varies. For example, Synology typically uses `/volume1/docker/msgvault`.
:::

## 3) Provision Gmail Tokens

For each mailbox:

1. Add account locally (requires browser):

```bash
msgvault add-account you@gmail.com
```

2. Export the token to the remote endpoint:

```bash
msgvault export-token you@gmail.com \
  --to http://nas-ip:8080 --api-key YOUR_API_KEY --allow-insecure
```

:::note[Why `--allow-insecure`?]
`export-token` requires HTTPS by default to protect OAuth tokens in transit. On a home LAN with a private IP like `192.168.1.50`, HTTPS isn't practical (you can't get a TLS certificate for a private IP). Use `--allow-insecure` when the remote host is on a trusted network.

If you ran `msgvault setup` and configured a remote server, the wizard already set `allow_insecure = true` in your local config, so `--allow-insecure` is not needed on the command line.

For internet-facing deployments, put msgvault behind a reverse proxy with TLS (see [Security Recommendations](/docker/#https-reverse-proxy)).
:::

The command uploads to `POST /api/v1/auth/token/{email}` and also posts to `POST /api/v1/accounts` to register:

- default sync schedule `0 2 * * *`
- account enabled

If you did not configure remote details during setup, you can also set:

```bash
export MSGVAULT_REMOTE_URL=http://nas-ip:8080
export MSGVAULT_REMOTE_API_KEY=YOUR_API_KEY
msgvault export-token you@gmail.com --allow-insecure
```

## 4) Run Initial Full Sync

The scheduler and sync API run **incremental** syncs only, which require a completed full sync to work. Run the initial full sync inside the container:

```bash
# Required — scheduled sync will not work without this
docker exec msgvault msgvault sync-full you@gmail.com

# Optional: test with a small batch first
docker exec msgvault msgvault sync-full you@gmail.com --limit 100
```

After the full sync completes, scheduled syncs run automatically on the cron schedule registered during token export (`0 2 * * *` by default). You can also trigger a manual sync via the API:

```bash
# Trigger incremental sync via API (only works after full sync)
curl -X POST -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/sync/you@gmail.com

# Check schedule status
curl -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/scheduler/status
```

## Using the Local CLI Against Remote

When your local machine config has:

```toml
[remote]
url = "http://remote-host:8080"
api_key = "YOUR_API_KEY"
allow_insecure = true
```

`search`, `stats`, `list-accounts`, and `show-message` automatically query the remote API.
Use `--local` if you explicitly want to query local SQLite instead.

## Security Notes

- **API key protects all API access.** The server requires `api_key` for non-loopback addresses. Anyone with the key can read your entire archive, so treat it like a password.
- **HTTP is fine on a trusted LAN.** If your NAS is on a home network behind a router, HTTP with an API key is reasonable. The setup wizard generates HTTP URLs by default.
- **Use HTTPS for internet-facing deployments.** Put msgvault behind a reverse proxy with TLS (Caddy, nginx, Traefik). See [Security Recommendations](/docker/#https-reverse-proxy).
- **Tailscale** is a good middle ground — it encrypts traffic without needing certificates. Use your Tailscale hostname with HTTPS, or HTTP with `--allow-insecure`.
- The generated bundle sets `user: root` in Docker Compose, which works around common NAS ACL quirks (for example Synology). On a standard Linux server you can change this to a non-root user.

## Troubleshooting

### Export fails with HTTPS required

`msgvault export-token` requires HTTPS by default. If your endpoint is `http://`, add `--allow-insecure`.

### 401/authorization errors from export

Check that `X-API-Key` matches the server's `[server] api_key` and that `/api/v1/auth/token/{email}` is reachable.

### Sync fails with "no history ID" or "run full sync first"

The scheduler and sync API only run incremental syncs. You must run a full sync first:

```bash
docker exec msgvault msgvault sync-full you@gmail.com
```

### Account not syncing after import

Verify the account exists in the server config:

```bash
curl -H "X-API-Key: YOUR_API_KEY" http://remote-host:8080/api/v1/accounts
```

If missing, re-run `export-token`, which also posts account metadata.
